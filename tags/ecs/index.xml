<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ECS on https://auerl.github.io</title>
    <link>/tags/ecs/</link>
    <description>Recent content in ECS on https://auerl.github.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019</copyright>
    <lastBuildDate>Mon, 18 Mar 2019 23:05:47 +0100</lastBuildDate>
    
	<atom:link href="/tags/ecs/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Building a scalable batch processing pipeline for sensor fusion using Docker, Luigi, ECS and S3</title>
      <link>/post/tracktics-data-pipeline/</link>
      <pubDate>Mon, 18 Mar 2019 23:05:47 +0100</pubDate>
      
      <guid>/post/tracktics-data-pipeline/</guid>
      <description>Introduction At TRACKTICS we developed a GNSS/IMU based sensor hardwardware tailored for the application of logging movements of a football player during game or training sessions.
 Low price of the sensor hardware for a low entry-barrier, such allowing to be eligible for the mass-market and tight budgets. Th Provide data quickly, robustly and at low cloud infrastructure operation costs Accurate results  This meant we had to develop algorithms that are cost intensive, batch style sensor fusion, with high memory, optimization based algorithm.</description>
    </item>
    
    <item>
      <title>Data analysis pipeline</title>
      <link>/project/data-pipelines/</link>
      <pubDate>Fri, 28 Dec 2018 11:27:00 +0100</pubDate>
      
      <guid>/project/data-pipelines/</guid>
      <description>The TRACKTICS Pipeline is a framework that allows to orchestrate parallel DAG (Direct Acyclic Graphs) batch processing jobs. It is based on Docker for artifact deployment, ECS (Amazon EC2 Container Service) for container orchestration and resource discovery, Luigi (by Spotify) for workflow and dependency management, SQS (Amazon Simple Queuing System) as a job queue, a custom autoscaler, S3 and Postgres (Amazon RDS) to store results and Kinesis to for logging. On a service level our toolbox features a universal Python wrapper that allows to expose the functionality of each service to ECS and the workflow manager, in a consistent way.</description>
    </item>
    
  </channel>
</rss>